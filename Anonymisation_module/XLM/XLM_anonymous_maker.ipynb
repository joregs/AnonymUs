{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T18:58:06.461840Z",
     "start_time": "2025-03-19T18:57:57.929900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline"
   ],
   "id": "652e3a925b5abc69",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T18:58:09.026744Z",
     "start_time": "2025-03-19T18:58:06.479706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_checkpoint = \"xlm-roberta-large-finetuned-conll03-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint)"
   ],
   "id": "67421b8a0da27635",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-large-finetuned-conll03-english were not used when initializing XLMRobertaForTokenClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T18:58:09.112590Z",
     "start_time": "2025-03-19T18:58:09.102563Z"
    }
   },
   "cell_type": "code",
   "source": "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")",
   "id": "87a77b8e6b4ca20e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T18:58:10.080983Z",
     "start_time": "2025-03-19T18:58:09.184396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "text = \"Elon Musk founded Tesla in California on March 12, 2024, and 2003.\"\n",
    "\n",
    "\n",
    "entities = ner_pipeline(text)\n",
    "\n",
    "for entity in entities:\n",
    "    print(f\"Word: {entity['word']}, Entity: {entity['entity_group']}, Score: {entity['score']:.2f}\")\n"
   ],
   "id": "ef14c314409161c3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: Elon Musk, Entity: PER, Score: 1.00\n",
      "Word: Tesla, Entity: ORG, Score: 1.00\n",
      "Word: California, Entity: LOC, Score: 1.00\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T18:58:10.986612Z",
     "start_time": "2025-03-19T18:58:10.213614Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "\n",
    "anonymize_types = [\"PER\", \"ORG\", \"LOC\"]\n",
    "\n",
    "\n",
    "date_patterns = [\n",
    "    r\"\\b\\d{1,2}/\\d{1,2}/\\d{2,4}\\b\",  # MM/DD/YYYY or DD/MM/YYYY\n",
    "    r\"\\b\\d{4}-\\d{1,2}-\\d{1,2}\\b\",    # YYYY-MM-DD\n",
    "    r\"\\b\\d{1,2} (Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]* \\d{4}\\b\",  # \"12 March 2024\"\n",
    "    r\"\\b(January|February|March|April|May|June|July|August|September|October|November|December) \\d{1,2},? \\d{4}\\b\",  # \"March 12, 2024\"\n",
    "    r\"\\b\\d{4}\\b\"  # Any 4-digit year (e.g., \"2003\")\n",
    "]\n",
    "\n",
    "\n",
    "def anonymize_text(text):\n",
    "    entities = ner_pipeline(text)\n",
    "\n",
    "   \n",
    "    for entity in entities:\n",
    "        if entity[\"entity_group\"] in anonymize_types:\n",
    "            text = text.replace(entity[\"word\"], \"XXX\")\n",
    "\n",
    "  \n",
    "    for pattern in date_patterns:\n",
    "        text = re.sub(pattern, \"XXX\", text)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "input_text = \"\"\"In 2021, Dr. Jonathan Reed and his assistant, Emily Carter, conducted an unauthorized experiment at the Blackwood Research Facility in Germany. \n",
    "The experiment, named Project Genesis, involved exposing ten subjects—such as Michael Turner and Sarah Williams—to an untested neurochemical compound.\n",
    "\"\"\"\n",
    "anonymized_text = anonymize_text(input_text)\n",
    "\n",
    "print(\"Anonymized Text:\\n\", anonymized_text)\n"
   ],
   "id": "1b807e860677a867",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anonymized Text:\n",
      " In XXX, Dr. XXX and his assistant, XXX, conducted an unauthorized experiment at the XXX in XXX. \n",
      "The experiment, named Project Genesis, involved exposing ten subjects—such as XXX and XXX—to an untested neurochemical compound.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
